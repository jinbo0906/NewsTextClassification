name: BERTClass
conf:
  bert:
#    activate: "relu"
    norm: False
    layer_size: [ 100, 100, 100, 100 ]
    lstm_in_dim: 512
    lstm_hid_dim: 64
    lstm_layer_n: 1
load_checkpoint: False
checkpoint_path: "./"